{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lec 7 & 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closed form gradient: for xp = -0.3278, for yp = -0.3363\n",
      "closed form loss = 0.4431\n"
     ]
    }
   ],
   "source": [
    "#create data normal gradient way\n",
    "from random import Random\n",
    "from math import sqrt\n",
    "\n",
    "seed = 5\n",
    "n = 1000\n",
    "epochs = 3\n",
    "\n",
    "def genPnts(n=n):\n",
    "    rand_gen = Random(x=seed)\n",
    "    data_x = [ rand_gen.uniform(a=0, b=1) for _ in range(n) ]\n",
    "    data_y = [ rand_gen.uniform(a=0, b=1) for _ in range(n) ]\n",
    "    return data_x, data_y\n",
    "# closed form estimtaion of gradient\n",
    "def grad(X, Y, xp, yp, n=n):\n",
    "    sum_x, sum_y = 0., 0.\n",
    "    for xi, yi in zip(X, Y):\n",
    "        temp = ((xi - xp)**2 + (yi - yp)**2) ** (-0.5)\n",
    "        sum_x += temp * (xi - xp)\n",
    "        sum_y += temp * (yi - yp)\n",
    "    return - sum_x / n, - sum_y / n\n",
    "\n",
    "def loss(X, Y, xp, yp, n=n):\n",
    "    return (1/n) * sum(\n",
    "        [ sqrt((xi - xp)**2 + (yi - yp)**2)\n",
    "        for xi, yi in zip(X, Y) ]\n",
    "    )\n",
    "\n",
    "data_x, data_y = genPnts(n=n)\n",
    "\n",
    "xp, yp = 0.3, 0.3\n",
    "grad_x, grad_y = grad(data_x, data_y, xp, yp, n)\n",
    "loss_clsd = loss(data_x, data_y, xp, yp, n)\n",
    "\n",
    "print(f\"closed form gradient: for xp = {grad_x:.4f}, for yp = {grad_y:.4f}\")\n",
    "print(f\"closed form loss = {loss_clsd:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch as an example of Autograd engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 2]) torch.Size([2])\n",
      "torchloss: 0.44305282831192017\n",
      "torchloss: tensor([-0.3278, -0.3363])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "point = torch.tensor([0.3, 0.3])\n",
    "point.requires_grad = True\n",
    "point.retain_grad()\n",
    "data_x, data_y = genPnts(n=n)\n",
    "data= torch.tensor([data_x, data_y])\n",
    "# i want my data to represent a row\n",
    "data= data.t()\n",
    "print(data.shape, point.shape)\n",
    "\n",
    "loss_torch= torch.mean(torch.sqrt(((data- point)**2).sum(dim=1))) # bec i'm summing in columns\n",
    "print(f\"torchloss: {loss_torch}\")\n",
    "loss_torch.backward()\n",
    "print(f\"torchloss: {point.grad.data}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulding Autorad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class comp_node:\n",
    "    def __init__(self , val, children):\n",
    "        self.val=val\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
